"""
Simple Year-End Party Chatbot - Streamlit App
Input: MSNV -> Output: AI Response
"""
from urllib import response
import streamlit as st
import pandas as pd
pd.set_option('display.max_columns', None)
# Show full text in DataFrame
pd.set_option('display.max_colwidth', None)
import json
from io import BytesIO
from google import genai
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from office365.sharepoint.client_context import ClientContext
from office365.runtime.auth.user_credential import UserCredential
from office365.sharepoint.files.file import File
from dotenv import load_dotenv
import os
import time

load_dotenv()

# ==================== Page Config ====================
st.set_page_config(
    page_title="Year-End Party Chatbot",
    page_icon="ğŸ‰",
    layout="centered"
)

# ==================== Custom CSS ====================
st.markdown("""
<style>
    .main {
        background: linear-gradient(135deg, #0f2027 0%, #1c3c72 50%, #2a5298 100%);
        color: white;
    }
    .stButton>button {
        width: 100%;
        background: linear-gradient(135deg, #FFF8B0 0%, #FFFCC2 50%, #FFF59D 100%);
        box-shadow: 0 0 5px #FFF59D, 0 0 10px #FFFCC2;
        color: #0f2027;
        border-radius: 12px;
        padding: 10px;
        font-size: 16px;
        border-radius: 10px;
        font-weight: bold;
    }
    .result-box {
        background-color: white;
        padding: 20px;
        border-radius: 15px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        margin-top: 20px;
        color: black;
    }
</style>
""", unsafe_allow_html=True)

# ==================== Functions ====================
@st.cache_resource
def get_ai_model():
    """Initialize AI model (cached)"""
    client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
    model = ChatGoogleGenerativeAI(
                                    model=os.getenv("AI_MODEL"),
                                    api_key=os.getenv("GEMINI_API_KEY"),
                                    temperature=1.0,
                                    max_output_tokens=3000,
                                    thinking_level="minimal",
                                    )
    return model

@st.cache_data(ttl=1)  # Cache for 1 second 
def connect_to_sharepoint(refresh_key=0):
    """Connect to SharePoint and download Excel file"""
    site_url = os.getenv(
        "SHAREPOINT_SITE_URL",
        "https://mabmotor-my.sharepoint.com/personal/vnm13649_mabuchi-motor_com"
    )
    username = os.getenv("MICROSOFT_ACCOUNT")
    password = os.getenv("MICROSOFT_PASSWORD")
    file_relative_url = os.getenv(
        "SHAREPOINT_FILE_URL",
        "/personal/vnm13649_mabuchi-motor_com/Documents/Microsoft Teams Chat Files/guest_information 1.xlsx"
    )
    
    ctx = ClientContext(site_url).with_credentials(
        UserCredential(username, password)
    )
    
    response = File.open_binary(ctx, file_relative_url)
    file_stream = BytesIO(response.content)
    
    # ctx.web.get_file_by_server_relative_url(
    #     file_relative_url
    # ).download(file_stream).execute_query()
    
    file_stream.seek(0)
    raw = file_stream.getvalue()
    xls = pd.ExcelFile(file_stream)

    df = pd.read_excel(xls, "participants_profile")
    company_context = pd.read_excel(xls, "company_context")
    role_definition = pd.read_excel(xls, "role_definition")
    # print("company_context: ", company_context)
    # print("role_definition: ", role_definition)
    print("REFRESH KEY:", refresh_key)
    print("DOWNLOAD AT:", time.time())
    print("FILE SIZE:", len(raw))
    return df, company_context['text'][0], role_definition['text'][0]

def get_participant_by_id(user_id, use_sharepoint=True):
    """Get participant data by ID"""
    try:
        fix_response = None
        text_to_inject = None
        if use_sharepoint:
            df, company_context, role_definition = connect_to_sharepoint(st.session_state.refresh)
            # print("company_context after connect: ", company_context)
            # print("role_definition after connect: ", role_definition)
        else:
            # Fallback to local file
            df = pd.read_excel("data/guest_information.xlsx", sheet_name="participants_profile")
            company_context, role_definition = load_context_files()
            
        # kiá»ƒm tra náº¿u user_id lÃ  sá»‘ thÃ¬ tÃ¬m báº±ng "id", náº¿u khÃ´ng thÃ¬ tÃ¬m báº±ng "name"
        # print("Looking for user_id:", user_id, "of type", type(user_id))
        if isinstance(user_id, int) or ((isinstance(user_id, str) and user_id.isdigit())):      
            result = df[df["id"] == int(user_id)]
        elif isinstance(user_id, str):
            # print("Searching in list:", df["name"].tolist())
            result = df[df["name"].str.lower().str.strip() == user_id.lower().strip()]
        else:
            st.error("Nháº­p MSNV hoáº·c tÃªn há»£p lá»‡!")
            return None
        print("Result DataFrame:", result)
        if result.empty:
            st.error("KhÃ´ng tÃ¬m tháº¥y ngÆ°á»i nÃ y!")
            return None
        
        # Convert to dict and handle NaN
        data = result.iloc[0].to_dict()
        data = {k: (None if pd.isna(v) else v) for k, v in data.items()}
        
        # tÃ¡ch cá»™t fixed_response náº¿u cÃ³
        if "fixed_response" in data:
            # Ä‘á»•i thÃ nh NaN
            fix_response = data["fixed_response"]
            # xÃ³a luÃ´n khá»i data
            del data["fixed_response"]
        
        if "text_to_inject" in data:
            text_to_inject = data["text_to_inject"]
            del data["text_to_inject"]
        
        print("data:", data)
        print("User data retrieved:", data)
        print("Text to inject:", text_to_inject )
        return data, company_context, role_definition, fix_response, text_to_inject
        
    except Exception as e:
        st.error(f"Lá»—i khi láº¥y dá»¯ liá»‡u: {str(e)}")
        return None

@st.cache_data
def load_context_files():
    """Load company context and role definitions"""
    try:         
        with open("..\\data\\company_context.txt", "r", encoding="utf-8") as f:
            company_context = f.read()
    except:
        company_context = ""
    
    try:
        with open("..\\data\\role_definition.txt", "r", encoding="utf-8") as f:
            role_definition = f.read()
    except:
        role_definition = ""
    
    return company_context, role_definition

def generate_response(user_data, model, company_context, role_definition, text_to_inject=None ):
    
    if user_data['nationality'] == 'JP':
        language = "Tiáº¿ng Anh"
        user_prompt = "VÃ¬ Ä‘Ã¢y lÃ  ngÆ°á»i Nháº­t, hÃ£y tráº£ lá»i báº±ng tiáº¿ng Anh má»™t cÃ¡ch tá»± nhiÃªn vÃ  thÃ¢n thiá»‡n dá»±a vÃ o thÃ´ng tin cá»§a há»:"
    else:
        language = "Tiáº¿ng Viá»‡t"
        user_prompt = "ÄÃ¢y laÌ€ thÃ´ng tin cÃ¡ nhÃ¢n cá»§a ngÆ°á»i dÃ¹ng:"
        
    if text_to_inject:
        text_to_inject = f"\nHÃ£y Ä‘áº£m báº£o cÃ¢u bÃ³i cá»§a báº¡n cÃ³ chá»©a thÃ´ng tin sau Ä‘Ã¢y: {text_to_inject}"
    else:
        text_to_inject = ""
        
    system_prompt = f"""Báº¡n lÃ  má»™t chatbot bÃ³i toÃ¡n hÃ i hÆ°á»›c, thÃ´ng minh, nÃ³i chuyá»‡n lÆ°u loÃ¡t dÃ¹ng Ä‘á»ƒ giáº£i trÃ­ trong buá»•i tiá»‡c táº¥t niÃªn cá»§a cÃ´ng ty.
PHáº¢I LUÃ”N NHá»š Ráº°NG NÄ‚M NAY LÃ€ NÄ‚M 2025 (NÄ‚M SAU LÃ€ NÄ‚M 2026).
Báº¡n sáº½ dá»±a vÃ o thÃ´ng tin cÃ¡ nhÃ¢n cá»§a ngÆ°á»i dÃ¹ng Ä‘á»ƒ Ä‘Æ°a ra cÃ¢u bÃ³i ngáº¯n gá»n, dá»… hiá»ƒu, hÃ i hÆ°á»›c vÃ  thÃº vá»‹.
HÃ£y cháº¯c cháº¯n ráº±ng cÃ¢u bÃ³i cá»§a báº¡n liÃªn quan trá»±c tiáº¿p Ä‘áº¿n thÃ´ng tin cÃ¡ nhÃ¢n cá»§a ngÆ°á»i dÃ¹ng.
HÃ£y sá»­ dá»¥ng ngÃ´n ngá»¯ tá»± nhiÃªn, thÃ¢n thiá»‡n vÃ  gáº§n gÅ©i, xÆ°ng hÃ´ "TÃ´i" vÃ  "Báº¡n".
HÃ£y thÃªm vÃ i icon lung linh vÃ o cÃ¢u bÃ³i Ä‘á»ƒ tÄƒng Ä‘á»™ háº¥p dáº«n, hoáº·c icon liÃªn quan Ä‘áº¿n ná»™i dung cÃ¢u bÃ³i.
HÃ£y trÃ¡nh sá»­ dá»¥ng cÃ¡c cá»¥m tá»« quÃ¡ trang trá»ng hoáº·c ká»¹ thuáº­t.
HÃ£y giá»¯ cÃ¢u bÃ³i khÃ´ng dÃ i quÃ¡ 200 tá»«.
HÃ£y tráº£ lá»i báº±ng {language}."""

    template = ChatPromptTemplate([
        SystemMessage(content=system_prompt),
        HumanMessage(content=[
            {"type": "text", "text": "HÃ£y sá»­ dá»¥ng bá»‘i cáº£nh cÃ´ng ty sau Ä‘Ã¢y Ä‘á»ƒ hiá»ƒu vá» vÄƒn hÃ³a vÃ  mÃ´i trÆ°á»ng lÃ m viá»‡c cá»§a cÃ´ng ty: "},
            {"type": "text", "text": company_context},
            {"type": "text", "text": "HÃ£y sá»­ dá»¥ng Ä‘á»‹nh nghÄ©a vai trÃ² sau Ä‘Ã¢y Ä‘á»ƒ hiá»ƒu vá» cÃ¡c vá»‹ trÃ­ cÃ´ng viá»‡c trong cÃ´ng ty: "},
            {"type": "text", "text": role_definition},
            {"type": "text", "text": user_prompt},
            {"type": "text", "text": json.dumps(user_data, ensure_ascii=False)},
            {"type": "text", "text": text_to_inject},
            {"type": "text", "text": "\nHÃ£y táº¡o má»™t cÃ¢u bÃ³i vui nhá»™n vÃ  may máº¯n cho ngÆ°á»i nÃ y!"}
        ])
    ])
    
    print("Generating response with template:", template.format_messages())
    
    # Generate response
    # response_chunks = []
    # for chunk in model.stream(template.format_messages()):
    #     if hasattr(chunk, 'content') and len(chunk.content) > 0:
    #         if isinstance(chunk.content, list):
    #             response_chunks.append(chunk.content[0].get('text', ''))
    #         else:
    #             response_chunks.append(chunk.content)
    
    # return ''.join(response_chunks).strip()
    response = model.invoke(template.format_messages())
    print("Generated response:", response)
    return response
# ==================== Main UI ====================
def main():
    # Header
    st.markdown("""
    <div style='text-align: center; padding: 20px;'>
        <h1 style='color: #FFF59D;'>ğŸ‰ Year-End Party Chatbot ğŸŠ</h1>
        <p style='color: #FFF59D; font-size: 1.2em;'>ğŸ§™â€â™‚ï¸ BÃ³i toÃ¡n vui nhá»™n cho bá»¯a tiá»‡c táº¥t niÃªn ğŸ’«</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Input form in white box
    with st.container():
        # st.markdown("<div class='result-box'>", unsafe_allow_html=True)
        
        with st.form(key="user_input_form"):
            st.markdown(" ğŸ—ï¸ Nháº­p MSNV hoáº·c tÃªn cá»§a báº¡n:")
            col1, col2 = st.columns([3, 1])
            
            with col1:
                user_id = st.text_input(
                    "Nháº­p MSNV cá»§a báº¡n:",
                    placeholder="VÃ­ dá»¥: 45678",
                    key="user_id_input"
                )
            
            with col2:
                st.write("")  # Spacing
                st.write("")  # Spacing
                submit_button = st.form_submit_button("ğŸª„ BÃ³i ngay!") 
        
        # st.markdown("</div>", unsafe_allow_html=True)
        
    if "refresh" not in st.session_state:
        st.session_state.refresh = 0

    if st.button("ğŸ”„ Reload Excel from SharePoint"):
        st.cache_data.clear()
        st.session_state.refresh += 1
        # add loading spinner
        with st.spinner("Loading data from SharePoint..."): 
            time.sleep(30)  # Wait for cache to clear and data to reload
        st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c táº£i láº¡i!")

        

    # Process when button clicked
    if submit_button and user_id:
        print("Processing user ID:", user_id, type(user_id))
        try:
            user_id_int = user_id
            
            with st.spinner("ğŸ”® Äang bÃ³i toÃ¡n cho báº¡n..."):
                # Get user data
                user_data, company_context, role_definition, fixed_response, text_to_inject = get_participant_by_id(user_id_int, True)
                
                if not user_data:
                    st.error("âŒ KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin vá»›i MSNV nÃ y!")
                    return
                # print("user_data retrieved:", user_data)
                # Load context
                print("company_context length:", len(company_context))
                # Get AI model
                model = get_ai_model()
                print("AI model initialized:", model)
                # Generate response
                if fixed_response is not None:
                    print("Using fixed response from data.")
                    response = fixed_response
                else:
                    response = generate_response(user_data, model, company_context, role_definition, text_to_inject)
                    
                    print("AI response metadata:")
                    print("input tokens:", response.usage_metadata['input_tokens'])
                    print("output tokens:", response.usage_metadata['output_tokens'])
                    response = response.content[0]['text']
            # Display result
            st.markdown("<div class='result-box'>", unsafe_allow_html=True)
            st.markdown(f"<h3 style='color: #FFF59D;'> {user_data.get('name', 'Báº¡n')} </h3>", unsafe_allow_html=True)
            
            if 'team' in user_data and user_data['team']:
                st.markdown(f"**ğŸª NhÃ³m:** {user_data['team']}")
            
            st.markdown("---")
            st.markdown(f"<h3 style='color: #FFF59D;'>ğŸ”® Lá»i bÃ³i cá»§a báº¡n:</h3>", unsafe_allow_html=True)
            st.markdown(response)
            st.markdown("</div>", unsafe_allow_html=True)
            
            # Try again button
            if st.button("ğŸ”„ BÃ³i láº¡i cho ngÆ°á»i khÃ¡c"):
                st.rerun()
                
        except ValueError:
            st.error("âŒ MSNV pháº£i lÃ  sá»‘!")
        except Exception as e:
            st.error(f"âŒ CÃ³ lá»—i xáº£y ra: {str(e)}")
    
    elif submit_button:
        st.warning("âš ï¸ Vui lÃ²ng nháº­p MSNV!")
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: white;'>
        <p>ğŸ’¡ <strong>LÆ°u Ã½:</strong> MSNV lÃ  mÃ£ sá»‘ nhÃ¢n viÃªn cá»§a báº¡n</p>
        <p>Made with â¤ï¸ for Year-End Party 2025</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()